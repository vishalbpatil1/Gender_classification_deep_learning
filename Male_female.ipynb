{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cvlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# initial parameters\n",
    "epochs = 100\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "img_dims = (96,96,3)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# load image files from the dataset\n",
    "image_files = [f for f in glob.glob(r'C:\\Files\\gender_dataset_face' + \"/**/*\", recursive=True) if not os.path.isdir(f)]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# converting images to arrays and labelling the categories\n",
    "for img in image_files:\n",
    "\n",
    "    image = cv2.imread(img)\n",
    "    \n",
    "    image = cv2.resize(image, (img_dims[0],img_dims[1]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    label = img.split(os.path.sep)[-2] # C:\\Files\\gender_dataset_face\\woman\\face_1162.jpg\n",
    "    if label == \"woman\":\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "        \n",
    "    labels.append([label]) # [[1], [0], [0], ...]\n",
    "\n",
    "# pre-processing\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# split dataset for training and validation\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "trainY = to_categorical(trainY, num_classes=2) # [[1, 0], [0, 1], [0, 1], ...]\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# augmenting datset \n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# define model\n",
    "def build(width, height, depth, classes):\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\": #Returns a string, either 'channels_first' or 'channels_last'\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "    \n",
    "    # The axis that should be normalized, after a Conv2D layer with data_format=\"channels_first\", \n",
    "    # set axis=1 in BatchNormalization.\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "# build model\n",
    "model = build(width=img_dims[0], height=img_dims[1], depth=img_dims[2],\n",
    "                            classes=2)\n",
    "\n",
    "# compile the model\n",
    "opt = Adam(lr=lr, decay=lr/epochs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "                        validation_data=(testX,testY),\n",
    "                        steps_per_epoch=len(trainX) // batch_size,\n",
    "                        epochs=epochs, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "model.save('gender_detection.model')\n",
    "\n",
    "# plot training/validation loss/accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0,N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0,N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0,N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0,N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "# save plot to disk\n",
    "plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import cvlib as cv\n",
    "                    \n",
    "# load model\n",
    "model = load_model('gender_detection.model')\n",
    "\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    "    \n",
    "classes = ['man','woman']\n",
    "\n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    "\n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "\n",
    "    # apply face detection\n",
    "    face, confidence = cv.detect_face(frame)\n",
    "\n",
    "\n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "\n",
    "        # get corner points of face rectangle        \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "\n",
    "        # draw rectangle over face\n",
    "        cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "\n",
    "        # crop the detected face region\n",
    "        face_crop = np.copy(frame[startY:endY,startX:endX])\n",
    "\n",
    "        if (face_crop.shape[0]) < 10 or (face_crop.shape[1]) < 10:\n",
    "            continue\n",
    "\n",
    "        # preprocessing for gender detection model\n",
    "        face_crop = cv2.resize(face_crop, (96,96))\n",
    "        face_crop = face_crop.astype(\"float\") / 255.0\n",
    "        face_crop = img_to_array(face_crop)\n",
    "        face_crop = np.expand_dims(face_crop, axis=0)\n",
    "\n",
    "        # apply gender detection on face\n",
    "        conf = model.predict(face_crop)[0] # model.predict return a 2D matrix, ex: [[9.9993384e-01 7.4850512e-05]]\n",
    "\n",
    "        # get label with max accuracy\n",
    "        idx = np.argmax(conf)\n",
    "        label = classes[idx]\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(label, conf[idx] * 100)\n",
    "\n",
    "        Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\n",
    "        # write label and confidence above face rectangle\n",
    "        cv2.putText(frame, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # display output\n",
    "    cv2.imshow(\"gender detection\", frame)\n",
    "\n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
